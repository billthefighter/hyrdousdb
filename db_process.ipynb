{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hydrous DB importer / manager\n",
    "Writen by LW/ES 20171224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declarations and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T18:48:35.017000Z",
     "start_time": "2018-01-05T18:48:35.007000Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import glob2\n",
    "import json\n",
    "import io\n",
    "import piexif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "declare globals and init variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T20:47:15.432000Z",
     "start_time": "2018-01-05T20:47:15.426000Z"
    }
   },
   "outputs": [],
   "source": [
    "#Make sure to change root directory to the directory where your  image file structure starts - will add GUI in future but for now this is fastest. \n",
    "\n",
    "#--------------------------------CHANGE DIRECTORY BELOW------------------\n",
    "rootdir = '/Users/lucas/Documents/hydrousdb/hyrdousdb/data'\n",
    "#----------------------------------------------------------\n",
    "#rootdir = 'C:\\\\Users\\\\lucasw\\\\Documents\\\\hyrdousdb\\\\data\\\\'\n",
    "searchdir = rootdir + '/**/*'\n",
    "twod_extention_list = ['.jpg','.png']\n",
    "threed_extention_list = ['.obj', '.stl']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T18:49:48.983000Z",
     "start_time": "2018-01-05T18:49:48.971000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\lucasw\\\\Documents\\\\hyrdousdb'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# static functions\n",
    "os.getcwd() # just a quick reference to see what our current working directory (CWD) is. Doesn't need to be run.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "declare classes - These are the objects that make up our database before converting to a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T18:50:06.680000Z",
     "start_time": "2018-01-05T18:50:06.601000Z"
    }
   },
   "outputs": [],
   "source": [
    "class commondata(object):\n",
    "    def __iter__(self):\n",
    "        for attr, value in self.__dict__.iteritems(): #only return indicies\n",
    "            yield attr, value\n",
    "    def __str__(self):\n",
    "        return \"This is data common to all data sources\"\n",
    "    def __init__(self):\n",
    "        #input from text file, init to blank\n",
    "        self.textfile_data = {'projname' : '',\n",
    "                              'date' : '',\n",
    "                              'location' : '',\n",
    "                              'latitude' : '',\n",
    "                              'longitude' : '',\n",
    "                              'photographer' : '',\n",
    "                              'species' : '',\n",
    "                             }\n",
    "        \n",
    "        #passed from program\n",
    "        self.file_info = {'filename' : '',\n",
    "                          'file_extension' : '',\n",
    "                          'fileroot' : '',\n",
    "                          'size' : ''\n",
    "                          }\n",
    "        \n",
    "\n",
    "\n",
    "    def importfromtext(self, import_textfile): \n",
    "        self.textfile_data = import_textfile.textfile_data\n",
    "\n",
    "class info_text_file(commondata):\n",
    "    def __str__(self):\n",
    "        return \"This is a metadata object, which inherets a lot of parameters from commondata class.\"\n",
    "    def __init__(self, filename, fileroot):\n",
    "        commondata.__init__(self)\n",
    "        self.file_info['filename'] = filename\n",
    "        self.file_info['fileroot'] = fileroot        \n",
    "    def process(self):\n",
    "        print( 'found json file ' + self.file_info['filename'] +', importing values')\n",
    "        with open(self.file_info['filename'], 'r') as f:\n",
    "            datastore = json.load(f)\n",
    "        #this might be more effecient if we make a common function which iterates through keys\n",
    "        for key in datastore:\n",
    "            if key in self.textfile_data:\n",
    "                self.textfile_data[key] = datastore[key]\n",
    "            if key not in self.textfile_data:\n",
    "                print( \"Warning, extra data found in JSON, appending to new key \" + key)\n",
    "                self.textfile_data[key] = datastore[key]\n",
    "            \n",
    "\n",
    "      \n",
    "class twod_img(commondata):\n",
    "    def __str__(self):\n",
    "        return \"This is a 2d image object, which inherets a lot of parameters from commondata class.\"\n",
    "    def __init__(self, filename, file_extension, fileroot):\n",
    "        commondata.__init__(self)\n",
    "        self.file_info['filename'] = filename\n",
    "        self.file_info['fileroot'] = fileroot\n",
    "        self.file_info['file_extension'] = file_extension\n",
    "        self.file_info['size'] = os.path.getsize(self.file_info['filename'])\n",
    "        self.supplemental_data = {'resolution' : '',\n",
    "                          'colorcorrected_image' : False\n",
    "                         }\n",
    "        \n",
    "        \n",
    "    def extract_exif(self):\n",
    "        exif_dict = piexif.load(self.file_info['filename'])\n",
    "        #dump(exif_dict) #- Get exif as bytes to save with JPEG.\n",
    "        #insert(exif_bytes, filename) #- Insert exif into JPEG.\n",
    "        #remove(filename) #- Remove exif from JPEG.)\n",
    "\n",
    "        #extract exif data from 2d image\n",
    "\n",
    "class threed_model(commondata):\n",
    "    def __str__(self):\n",
    "        return \"This is a 3d model object, which inherets a lot of parameters from commondata class.\"\n",
    "    def __init__(self, filename, file_extension, fileroot):\n",
    "        commondata.__init__(self)\n",
    "        self.file_info['filename'] = filename\n",
    "        self.file_info['fileroot'] = fileroot\n",
    "        self.file_info['file_extension'] = file_extension\n",
    "        self.file_info['size'] = os.path.getsize(self.file_info['filename'])\n",
    "        self.supplemental_data = {}\n",
    "        \n",
    "    #def collect_files(self):\n",
    "        #create associative link between texture, 3d, and other files of same model (.mtl, .obj, .jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T18:50:18.574000Z",
     "start_time": "2018-01-05T18:50:18.520000Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\1-Model-Verticle wall_jpodgs\\data copy.json\n",
      "found json file C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\1-Model-Verticle wall_jpodgs\\data copy.json, importing values\n",
      "C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\1-Model-Verticle wall_jpodgs\\data.json\n",
      "found json file C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\1-Model-Verticle wall_jpodgs\\data.json, importing values\n",
      "C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\2-Model-Blue soft coral-jpgs\\data.json\n",
      "found json file C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\2-Model-Blue soft coral-jpgs\\data.json, importing values\n",
      "WARNING: json file found in subdirectory. Ignoring C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\2-Model-Blue soft coral-jpgs\\data.json\n",
      "WARNING: Filetype not recognized, ignoring C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\2-Model-Blue soft coral-jpgs\\data.json\n",
      "WARNING: Filetype not recognized, ignoring C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\2-Model-Blue soft coral-jpgs\\info_text.rtf\n",
      "WARNING: json file found in subdirectory. Ignoring C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\1-Model-Verticle wall_jpodgs\\data copy.json\n",
      "WARNING: Filetype not recognized, ignoring C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\1-Model-Verticle wall_jpodgs\\data copy.json\n",
      "WARNING: json file found in subdirectory. Ignoring C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\1-Model-Verticle wall_jpodgs\\data.json\n",
      "WARNING: Filetype not recognized, ignoring C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\1-Model-Verticle wall_jpodgs\\data.json\n",
      "WARNING: Filetype not recognized, ignoring C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\1-Model-Verticle wall_jpodgs\\info_text.rtf\n",
      "WARNING: Filetype not recognized, ignoring C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\1-Model-Verticle wall_jpodgs\\raw\n",
      "WARNING: json file found in subdirectory. Ignoring C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\1-Model-Verticle wall_jpodgs\\data copy.json\n",
      "WARNING: Filetype not recognized, ignoring C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\1-Model-Verticle wall_jpodgs\\data copy.json\n",
      "WARNING: json file found in subdirectory. Ignoring C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\1-Model-Verticle wall_jpodgs\\data.json\n",
      "WARNING: Filetype not recognized, ignoring C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\1-Model-Verticle wall_jpodgs\\data.json\n",
      "WARNING: Filetype not recognized, ignoring C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\1-Model-Verticle wall_jpodgs\\info_text.rtf\n",
      "WARNING: Filetype not recognized, ignoring C:\\Users\\lucasw\\Documents\\hyrdousdb\\data\\1-Model-Verticle wall_jpodgs\\raw\n"
     ]
    }
   ],
   "source": [
    "import_dict = {}\n",
    "json_identifier_dict = {}\n",
    "\n",
    "for f in glob2.iglob(searchdir + '.json'):\n",
    "    fileroot = os.path.dirname(f)\n",
    "    if fileroot in json_identifier_dict:\n",
    "        print('WARNING: multiple text files found in folder, ignoring ' + f)\n",
    "        pass\n",
    "    if fileroot not in json_identifier_dict :    \n",
    "        json_identifier_dict[f] = info_text_file(f, fileroot)\n",
    "        json_identifier_dict[f].process() #process the metadata\n",
    "#need to check for nested .json files to avoid problems.\n",
    "#create copy of json identifier dicts so it can be modified - dicts are immutable\n",
    "json_identifier_dict_cleaned = json_identifier_dict.copy()\n",
    "\n",
    "for key1 in json_identifier_dict:\n",
    "    for f in glob2.iglob(json_identifier_dict[key1].file_info['fileroot'] + '/*/**/*' + '.json'):\n",
    "        json_identifier_dict_cleaned.pop(f)\n",
    "        print('WARNING: json file found in subdirectory. Ignoring ' + f)\n",
    "        pass\n",
    "        \n",
    "for key in json_identifier_dict_cleaned:\n",
    "    for f in glob2.iglob(json_identifier_dict_cleaned[key].file_info['fileroot'] + '/**/*'):\n",
    "        filename, file_extension = os.path.splitext(f)\n",
    "        fileroot = os.path.dirname(f)\n",
    "        if file_extension in ['.json']:\n",
    "            print('WARNING: json file found in subdirectory. Ignoring ' + f)\n",
    "            pass\n",
    "        if file_extension in twod_extention_list:\n",
    "            import_dict[f] = twod_img(f, file_extension, fileroot)\n",
    "            import_dict[f].importfromtext(json_identifier_dict_cleaned[key])\n",
    "            pass\n",
    "        if file_extension in threed_extention_list:\n",
    "            import_dict[f] = threed_model(f, file_extension, fileroot)\n",
    "            import_dict[f].importfromtext(json_identifier_dict_cleaned[key])\n",
    "            pass\n",
    "        if file_extension not in threed_extention_list + twod_extention_list:\n",
    "            print('WARNING: Filetype not recognized, ignoring ' + f)\n",
    "            pass\n",
    "        else:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T20:54:58.724000Z",
     "start_time": "2018-01-05T20:54:58.691000Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Exported to: C:\\Users\\lucasw\\Documents\\hyrdousdb\n"
     ]
    }
   ],
   "source": [
    "#This block makes a pandas database from a dictionary, then it exports it to the current working directory.\n",
    "\n",
    "pandas_dict = []\n",
    "for key in import_dict:   \n",
    "    pandadict_element = {}\n",
    "    pandadict_element.update(import_dict[key].file_info)\n",
    "    pandadict_element.update(import_dict[key].textfile_data)\n",
    "    pandadict_element.update(import_dict[key].supplemental_data)\n",
    "    pandas_dict.append(pandadict_element)\n",
    "\n",
    "pandas_DF = pandas.DataFrame.from_dict(pandas_dict)\n",
    "\n",
    "#create a new DB with today's date and time - we can change this to update an existing DB in the future, but for now it's nice to have past versions for debug\n",
    "\n",
    "writer = pandas.ExcelWriter((\"Image_Database_{}.xlsx\".format(pandas.datetime.today().strftime('%y%m%d-%H%M%S'))))\n",
    "pandas_DF.to_excel(writer,'Image Database')\n",
    "writer.save()\n",
    "print('File Exported to: ' + os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ifd_name in exif_dict:\n",
    "    print(\"\\n{0} IFD:\".format(ifd_name))\n",
    "    for key in exif_dict[ifd_name]:\n",
    "        try:\n",
    "            print(key, exif_dict[ifd_name][key][:10])\n",
    "        except:\n",
    "            print(key, exif_dict[ifd_name][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Old / test functions - IGNORE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T18:50:26.355000Z",
     "start_time": "2018-01-05T18:50:26.348000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['extract_exif', 'file_info', 'importfromtext', 'supplemental_data', 'textfile_data']\n",
      "{'projname': u'maldives cruise', 'photographer': u'David Turtleman', 'file_extension': '.jpg', 'location': u'Pittsburgh', 'fileroot': 'C:\\\\Users\\\\lucasw\\\\Documents\\\\hyrdousdb\\\\data\\\\1-Model-Verticle wall_jpodgs\\\\raw', 'filename': 'C:\\\\Users\\\\lucasw\\\\Documents\\\\hyrdousdb\\\\data\\\\1-Model-Verticle wall_jpodgs\\\\raw\\\\20171211-_32B6235.jpg', 'date': u'20171227', 'longitude': 73.185691, 'latitude': 0.216724, 'species': u'Lame Coral', 'size': 14858279L}\n",
      "['extract_exif', 'file_info', 'importfromtext', 'supplemental_data', 'textfile_data']\n",
      "{'projname': u'maldives cruise', 'photographer': u'David Turtleman', 'file_extension': '.jpg', 'location': u'Pittsburgh', 'fileroot': 'C:\\\\Users\\\\lucasw\\\\Documents\\\\hyrdousdb\\\\data\\\\2-Model-Blue soft coral-jpgs', 'filename': 'C:\\\\Users\\\\lucasw\\\\Documents\\\\hyrdousdb\\\\data\\\\2-Model-Blue soft coral-jpgs\\\\20171211-_32B6326.jpg', 'date': u'20171227', 'longitude': 73.185691, 'latitude': 0.216724, 'species': u'Lame Coral', 'size': 8714950L}\n",
      "['extract_exif', 'file_info', 'importfromtext', 'supplemental_data', 'textfile_data']\n",
      "{'projname': u'maldives cruise', 'photographer': u'David Turtleman', 'file_extension': '.jpg', 'location': u'Pittsburgh', 'fileroot': 'C:\\\\Users\\\\lucasw\\\\Documents\\\\hyrdousdb\\\\data\\\\1-Model-Verticle wall_jpodgs\\\\raw', 'filename': 'C:\\\\Users\\\\lucasw\\\\Documents\\\\hyrdousdb\\\\data\\\\1-Model-Verticle wall_jpodgs\\\\raw\\\\20171211-_32B6236.jpg', 'date': u'20171227', 'longitude': 73.185691, 'latitude': 0.216724, 'species': u'Lame Coral', 'size': 14569010L}\n",
      "['extract_exif', 'file_info', 'importfromtext', 'supplemental_data', 'textfile_data']\n",
      "{'projname': u'maldives cruise', 'photographer': u'David Turtleman', 'file_extension': '.jpg', 'location': u'Pittsburgh', 'fileroot': 'C:\\\\Users\\\\lucasw\\\\Documents\\\\hyrdousdb\\\\data\\\\1-Model-Verticle wall_jpodgs\\\\raw', 'filename': 'C:\\\\Users\\\\lucasw\\\\Documents\\\\hyrdousdb\\\\data\\\\1-Model-Verticle wall_jpodgs\\\\raw\\\\20171211-_32B6234.jpg', 'date': u'20171227', 'longitude': 73.185691, 'latitude': 0.216724, 'species': u'Lame Coral', 'size': 14492374L}\n",
      "['extract_exif', 'file_info', 'importfromtext', 'supplemental_data', 'textfile_data']\n",
      "{'projname': u'maldives cruise', 'photographer': u'David Turtleman', 'file_extension': '.jpg', 'location': u'Pittsburgh', 'fileroot': 'C:\\\\Users\\\\lucasw\\\\Documents\\\\hyrdousdb\\\\data\\\\2-Model-Blue soft coral-jpgs', 'filename': 'C:\\\\Users\\\\lucasw\\\\Documents\\\\hyrdousdb\\\\data\\\\2-Model-Blue soft coral-jpgs\\\\20171211-_32B6325.jpg', 'date': u'20171227', 'longitude': 73.185691, 'latitude': 0.216724, 'species': u'Lame Coral', 'size': 9561535L}\n",
      "['extract_exif', 'file_info', 'importfromtext', 'supplemental_data', 'textfile_data']\n",
      "{'projname': u'maldives cruise', 'photographer': u'David Turtleman', 'file_extension': '.jpg', 'location': u'Pittsburgh', 'fileroot': 'C:\\\\Users\\\\lucasw\\\\Documents\\\\hyrdousdb\\\\data\\\\2-Model-Blue soft coral-jpgs', 'filename': 'C:\\\\Users\\\\lucasw\\\\Documents\\\\hyrdousdb\\\\data\\\\2-Model-Blue soft coral-jpgs\\\\20171211-_32B6327.jpg', 'date': u'20171227', 'longitude': 73.185691, 'latitude': 0.216724, 'species': u'Lame Coral', 'size': 8639590L}\n"
     ]
    }
   ],
   "source": [
    "fart = {}\n",
    "for key in import_dict:\n",
    "        attribute_index = [a for a in dir(import_dict[key]) if not a.startswith('__')]\n",
    "        print attribute_index \n",
    "        fart.update(import_dict[key].file_info)\n",
    "        fart.update(import_dict[key].textfile_data)\n",
    "        print fart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testjson = {'projname': 'testfile',\n",
    "           'date' : '20171227',\n",
    "           'location' : 'Maldives',http://localhost:8888/notebooks/hyrdousdb/db_process.ipynb#\n",
    "           'photographer' : 'Elle Stapleton',\n",
    "           'species' : 'Cool Coral',\n",
    "            'latitude' : 0.216724, \n",
    "            'longitude' : 73.185691\n",
    "           }\n",
    "json_string = json.dumps(testjson)\n",
    "fart = pandas.Series(testjson)\n",
    "fart\n",
    "fart.to_json('data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Got invalid value.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-a8787ffee8d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/lucas/Documents/hydrousdb/hyrdousdb/data/3-Model-Black coral-jpgs/20171211-_32B6368.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexif_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpiexif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexif_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mexif_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lucas/anaconda/envs/hydrousdb/lib/python2.7/site-packages/piexif/_load.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(input_data, key_is_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m                  \u001b[0;34m\"1st\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                  \"thumbnail\":None}\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mexifReader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ExifReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexifReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtiftag\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexif_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lucas/anaconda/envs/hydrousdb/lib/python2.7/site-packages/piexif/_load.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     81\u001b[0m                     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Got invalid value.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"\\xff\\xd8\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# JPEG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mapp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_exif_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Got invalid value."
     ]
    }
   ],
   "source": [
    "filepath = '/Users/lucas/Documents/hydrousdb/hyrdousdb/data/3-Model-Black coral-jpgs/20171211-_32B6368.jpg'\n",
    "exif_dict = piexif.load(filepath)\n",
    "for key in exif_dict:\n",
    "    print key\n",
    "print exif_dict\n",
    "\n",
    "o = io.BytesIO()\n",
    "thumb_im = Image.open(\"foo.jpg\")\n",
    "thumb_im.thumbnail((50, 50), Image.ANTIALIAS)\n",
    "thumb_im.save(o, \"jpeg\")\n",
    "thumbnail = o.getvalue()\n",
    "\n",
    "zeroth_ifd = {piexif.ImageIFD.Make: u\"Canon\",\n",
    "              piexif.ImageIFD.XResolution: (96, 1),\n",
    "              piexif.ImageIFD.YResolution: (96, 1),\n",
    "              piexif.ImageIFD.Software: u\"piexif\"\n",
    "              }\n",
    "exif_ifd = {piexif.ExifIFD.DateTimeOriginal: u\"2099:09:29 10:10:10\",\n",
    "            piexif.ExifIFD.LensMake: u\"LensMake\",\n",
    "            piexif.ExifIFD.Sharpness: 65535,\n",
    "            piexif.ExifIFD.LensSpecification: ((1, 1), (1, 1), (1, 1), (1, 1)),\n",
    "            }\n",
    "gps_ifd = {piexif.GPSIFD.GPSVersionID: (2, 0, 0, 0),\n",
    "           piexif.GPSIFD.GPSAltitudeRef: 1,\n",
    "           piexif.GPSIFD.GPSDateStamp: u\"1999:99:99 99:99:99\",\n",
    "           }\n",
    "first_ifd = {piexif.ImageIFD.Make: u\"Canon\",\n",
    "             piexif.ImageIFD.XResolution: (40, 1),\n",
    "             piexif.ImageIFD.YResolution: (40, 1),\n",
    "             piexif.ImageIFD.Software: u\"piexif\"\n",
    "             }\n",
    "\n",
    "exif_dict = {\"0th\":zeroth_ifd, \"Exif\":exif_ifd, \"GPS\":gps_ifd, \"1st\":first_ifd, \"thumbnail\":thumbnail}\n",
    "exif_bytes = piexif.dump(exif_dict)\n",
    "im = Image.open(\"foo.jpg\")\n",
    "im.thumbnail((100, 100), Image.ANTIALIAS)\n",
    "im.save(\"out.jpg\", exif=exif_bytes)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
